{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"competition","sourceId":88742,"databundleVersionId":10173359},{"sourceType":"kernelVersion","sourceId":222390171}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#This code optimizes hyperparameters for the final model. \n\n\n\n# =============================================================================\n# Briefing Summary:\n# This script is designed to perform data loading, preprocessing, and hyperparameter tuning \n# for a sales forecasting model using CatBoostRegressor on Kaggle datasets. The code reads \n# various CSV files, converts date columns, reduces memory usage by downcasting data types, \n# processes categorical features, splits the data into training and validation sets, and \n# uses RandomizedSearchCV with time series cross-validation to tune the model's hyperparameters. \n# Finally, it exports the best hyperparameters to a CSV file.\n# =============================================================================\n\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport gc\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-15T12:19:58.982623Z","iopub.execute_input":"2025-02-15T12:19:58.982845Z","iopub.status.idle":"2025-02-15T12:19:59.873117Z","shell.execute_reply.started":"2025-02-15T12:19:58.982824Z","shell.execute_reply":"2025-02-15T12:19:59.872385Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/rohlik-dataprep/__results__.html\n/kaggle/input/rohlik-dataprep/__notebook__.ipynb\n/kaggle/input/rohlik-dataprep/train_merged_corrected.csv\n/kaggle/input/rohlik-dataprep/__output__.json\n/kaggle/input/rohlik-dataprep/custom.css\n/kaggle/input/rohlik-sales-forecasting-challenge-v2/calendar.csv\n/kaggle/input/rohlik-sales-forecasting-challenge-v2/test_weights.csv\n/kaggle/input/rohlik-sales-forecasting-challenge-v2/inventory.csv\n/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv\n/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_test.csv\n/kaggle/input/rohlik-sales-forecasting-challenge-v2/solution.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n\n# Input files are imported to get training and testing dates of the competition. \n\nsales_train = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_train.csv')\nsales_test = pd.read_csv('/kaggle/input/rohlik-sales-forecasting-challenge-v2/sales_test.csv')\n\n# Tarih sütunlarını datetime formatına çevirme\nsales_train['date'] = pd.to_datetime(sales_train['date'])\nsales_test['date'] = pd.to_datetime(sales_test['date'])\n\n# Train veri seti için min ve max tarihleri\ntrain_min_date = sales_train['date'].min()\ntrain_max_date = sales_train['date'].max()\n\n# Test veri seti için min ve max tarihleri\ntest_min_date = sales_test['date'].min()\ntest_max_date = sales_test['date'].max()\n\n# Sonuçları yazdırma\nprint(\"Sales Train - En Küçük Tarih:\", train_min_date)\nprint(\"Sales Train - En Büyük Tarih:\", train_max_date)\nprint(\"Sales Test - En Küçük Tarih:\", test_min_date)\nprint(\"Sales Test - En Büyük Tarih:\", test_max_date)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-15T12:19:59.873989Z","iopub.execute_input":"2025-02-15T12:19:59.874430Z","iopub.status.idle":"2025-02-15T12:20:07.446905Z","shell.execute_reply.started":"2025-02-15T12:19:59.874399Z","shell.execute_reply":"2025-02-15T12:20:07.446133Z"}},"outputs":[{"name":"stdout","text":"Sales Train - En Küçük Tarih: 2020-08-01 00:00:00\nSales Train - En Büyük Tarih: 2024-06-02 00:00:00\nSales Test - En Küçük Tarih: 2024-06-03 00:00:00\nSales Test - En Büyük Tarih: 2024-06-16 00:00:00\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Memory is cleaned and preprocessed data is imported\n\n# Delete the loaded sales datasets to free memory\ndel sales_train\ndel sales_test\n\n# Force garbage collection to reclaim memory\ngc.collect()\n\n\ntrain_merged_corrected = pd.read_csv('/kaggle/input/rohlik-dataprep/train_merged_corrected.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:14:41.379180Z","iopub.execute_input":"2025-02-13T07:14:41.379493Z","iopub.status.idle":"2025-02-13T07:16:44.086233Z","shell.execute_reply.started":"2025-02-13T07:14:41.379467Z","shell.execute_reply":"2025-02-13T07:16:44.083230Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Setting Pandas options to display all columns (and optionally all rows)\npd.set_option('display.max_columns', None)  # Tüm sütunları göster\npd.set_option('display.max_rows', None)     # Tüm satırları göster (opsiyonel)\n\n\n\ntrain_merged_corrected=train_merged_corrected.drop(columns=['is_weekend','day_sin',\n 'day_cos','sales_max',\n 'sales_mean',\n 'sales_median',\n 'sales_std',\n 'sales_skew',\n 'sales_zero_ratio',\n 'total_orders_max',\n 'total_orders_mean',\n 'total_orders_median',\n 'total_orders_std',\n 'total_orders_skew',\n 'total_orders_zero_ratio','sell_price_main_max',\n 'sell_price_main_mean',\n 'sell_price_main_median',\n 'sell_price_main_std',\n 'sell_price_main_skew',\n 'sell_price_main_zero_ratio',\n 'total_discount_max',\n 'total_discount_mean',\n 'total_discount_median',\n 'total_discount_std',\n 'total_discount_skew',\n 'total_discount_zero_ratio','sales_yearly_q25',\n 'sales_yearly_q75','total_orders_yearly_q25',\n 'total_orders_yearly_q75',\n 'total_orders_yearly_zero_ratio',\n 'total_orders_yearly_cv','sell_price_main_yearly_q25',\n 'sell_price_main_yearly_q75',\n 'sell_price_main_yearly_zero_ratio',\n 'sell_price_main_yearly_cv','availability_yearly_max', 'total_discount_yearly_q25',\n 'total_discount_yearly_q75',\n 'total_discount_yearly_zero_ratio','days_to_next_closed', 'total_discount_yearly_min'])\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:16:44.089459Z","iopub.execute_input":"2025-02-13T07:16:44.089918Z","iopub.status.idle":"2025-02-13T07:16:44.103696Z","shell.execute_reply.started":"2025-02-13T07:16:44.089876Z","shell.execute_reply":"2025-02-13T07:16:44.102456Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Listing columns of the merged dataset\ntrain_merged_corrected.columns.tolist()\n\n# Defining columns to drop from X sets\ncolumns_to_drop = [\n    'unique_id', 'date'\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:16:44.105014Z","iopub.execute_input":"2025-02-13T07:16:44.105451Z","iopub.status.idle":"2025-02-13T07:16:44.123376Z","shell.execute_reply.started":"2025-02-13T07:16:44.105408Z","shell.execute_reply":"2025-02-13T07:16:44.122307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Custom function to reduce memory usage by converting columns to smaller data types\n\ndef reduce_mem_usage(df):\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type not in [object, 'category', 'datetime64[ns]']:\n            c_min = df[col].min()\n            c_max = df[col].max()\n\n            # tamsayı sütunlar\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                else:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                # float sütunlar\n                df[col] = df[col].astype(np.float32)\n                \n        elif col_type == object:\n            # Eğer gerçekte kategorik veya sayısal değilse, kategorik dönüştürebilirsiniz\n            # df[col] = df[col].astype('category')\n            pass\n    \n    end_mem = df.memory_usage().sum() / 1024**2\n    print(f\"Bellek kullanımı: {start_mem:.2f} MB -> {end_mem:.2f} MB\")\n    return df\ntrain_merged_corrected=  reduce_mem_usage  (train_merged_corrected)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:17:30.443790Z","iopub.execute_input":"2025-02-13T07:17:30.444207Z","iopub.status.idle":"2025-02-13T07:17:34.230994Z","shell.execute_reply.started":"2025-02-13T07:17:30.444178Z","shell.execute_reply":"2025-02-13T07:17:34.229679Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport gc\nimport cupy as cp  # GPU bellek yönetimi için\nimport numpy as np\nimport pandas as pd\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit, train_test_split\nfrom sklearn.metrics import mean_absolute_error\nimport matplotlib.pyplot as plt\n\n# ------------------------------\n# Bellek Temizleme Fonksiyonu\n# ------------------------------\ndef clean_gpu_memory():\n    gc.collect()\n    cp.get_default_memory_pool().free_all_blocks()\n\n\n# Converting 'date' column to datetime and sorting by date\ntrain_merged_corrected['date'] = pd.to_datetime(train_merged_corrected['date'])\ntrain_merged_corrected = train_merged_corrected.sort_values('date')\n\n\n# Temporarily dropping columns_to_drop to identify non-numeric and non-string column\ndf_temp = train_merged_corrected.drop(columns=columns_to_drop)\nnon_num_str_df = df_temp.select_dtypes(exclude=[\"number\", \"string\"])\ndel df_temp\ncategorical_features = non_num_str_df.columns.tolist()\ncategorical_features.append('product_unique_id')\n\ntrain_merged_corrected[categorical_features] = train_merged_corrected[categorical_features].astype('string')\nfor col in categorical_features:\n    train_merged_corrected[col] = train_merged_corrected[col].astype(str).fillna(\"-1\")\n\n\n\nsales_train = train_merged_corrected[\n    (train_merged_corrected['date'] >= pd.Timestamp('2020-08-01')) &\n    (train_merged_corrected['date'] <= pd.Timestamp('2024-06-02'))\n]\n\ndel non_num_str_df\nclean_gpu_memory()\n\n\nX_train, X_val, y_train, y_val = train_test_split(\n    sales_train.drop(columns=columns_to_drop + ['sales']),\n    sales_train['sales'],\n    test_size=0.1,\n    shuffle=False\n)\n\n# Taking the forecasting weights from dataset for wmae\ntrain_weight = X_train['weight']\nval_weight = X_val['weight']\nX_train = X_train.drop(['weight'], axis=1)\nX_val = X_val.drop(['weight'], axis=1)\n\n\nX_train[categorical_features] = X_train[categorical_features].astype(str)\nX_val[categorical_features] = X_val[categorical_features].astype(str)\n\n# Applying log1p transformation to target variables\n\ny_train_log = np.log1p(y_train)\ny_val_log = np.log1p(y_val)\n\nclean_gpu_memory()\n\n# ------------------------------\n# Hiperparametre Tuning: RandomizedSearchCV (GPU Bellek Sınırlandırması ile)\n# ------------------------------\nbase_model = CatBoostRegressor(\n    loss_function='MAE',\n    random_seed=42,\n    boosting_type='Ordered',\n    task_type='GPU',\n    thread_count=-1,\n    max_bin=128,\n    cat_features=categorical_features,\n    verbose=0,\n    early_stopping_rounds=10)\n\nparam_grid = {\n    'iterations': [200, 500, 1000],\n    'learning_rate': [0.05, 0.1, 0.2],\n    'depth': [6, 8, 10],\n    'l2_leaf_reg': [0.1, 1, 10],\n    'min_data_in_leaf': [20, 30, 40],\n    'bagging_temperature': [0.2, 0.5, 0.8],\n    'random_strength': [0.2, 0.5, 0.8]\n}\n\ntscv = TimeSeriesSplit(n_splits=3)\n\nrandom_search = RandomizedSearchCV(\n    estimator=base_model,\n    param_distributions=param_grid,\n    n_iter=100,  # ✅ Düzgün yazılmış\n    scoring='neg_mean_absolute_error',\n    cv=tscv,\n    verbose=50,\n    random_state=42,\n    n_jobs=1\n)\n\nclean_gpu_memory()\n\nprint(\"Starting hyperparameter tuning...\")\nrandom_search.fit(X_train, y_train_log, sample_weight=train_weight)\nbest_params = random_search.best_params_\nprint(\"Best Parameters from tuning:\", best_params)\n\nclean_gpu_memory()\n\n# ------------------------------\n# Best Hyperparameters Export\n# ------------------------------\nbest_params_df = pd.DataFrame([best_params])\nbest_params_df.to_csv(\"best_hyperparameters.csv\", index=False)\nprint(\"Best hyperparameters exported to 'best_hyperparameters.csv'\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T07:16:44.194396Z","iopub.status.idle":"2025-02-13T07:16:44.194925Z","shell.execute_reply":"2025-02-13T07:16:44.194707Z"}},"outputs":[],"execution_count":null}]}